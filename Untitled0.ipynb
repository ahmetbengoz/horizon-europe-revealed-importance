{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgECj/GsWNl3LSQOYu1J9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmetbengoz/horizon-europe-revealed-importance/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CMAS-CHR-OP — REAL PIPELINE (EJOR-STYLE)\n",
        "# - True event-based sync (picker–robot meetings)\n",
        "# - Time-expanded reservation (node+edge, cap=1)\n",
        "# - Real ALNS on decision variables (handover choices, robot assignment, robot routing)\n",
        "# - Benchmarks + Excel + Figure2 + Convergence\n",
        "# ============================================\n",
        "\n",
        "import math, random, time\n",
        "from collections import defaultdict, deque\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Reproducibility\n",
        "# -----------------------------\n",
        "MASTER_SEED = 123\n",
        "random.seed(MASTER_SEED)\n",
        "np.random.seed(MASTER_SEED)\n",
        "\n",
        "# -----------------------------\n",
        "# Experiment design (adjustable)\n",
        "# -----------------------------\n",
        "AISLES = [10, 20, 40]\n",
        "ITEMS  = [200, 1000]          # add 5000 when you are ready (runtime grows)\n",
        "DENS   = [\"low\",\"medium\",\"high\"]\n",
        "SEEDS_PER = 5                 # EJOR: 10+ (increase later)\n",
        "\n",
        "P_LIST = [2,5,10]\n",
        "R_LIST = [1,3,5,10]\n",
        "\n",
        "AISLE_LEN = 20                # y=1..L-1 storage, y=0 and y=L are cross-aisles/handovers\n",
        "CAP = 1                       # narrow-aisle capacity\n",
        "SERVICE = 4                   # meeting service time (time steps)\n",
        "BATCH_SIZE = 4                # picker batching to avoid zig-zag\n",
        "V_PICK = 1.0\n",
        "V_ROB  = 1.2                  # robot speed multiplier (can be >1)\n",
        "\n",
        "# ALNS budget\n",
        "ALNS_ITERS = 1500\n",
        "T0 = 40.0\n",
        "COOL = 0.997\n",
        "\n",
        "# -----------------------------\n",
        "# Warehouse model: Manhattan grid with aisles\n",
        "# Nodes are integer tuples (x,y)\n",
        "# - depot at (0,0)\n",
        "# - storage at x in [1..A], y in [1..L-1]\n",
        "# - handovers at aisle ends: (x,0) and (x,L)\n",
        "# -----------------------------\n",
        "\n",
        "def manhattan(a,b): return abs(a[0]-b[0]) + abs(a[1]-b[1])\n",
        "\n",
        "def gen_items(A, L, n, density, seed):\n",
        "    rnd_state = random.getstate()\n",
        "    np_state  = np.random.get_state()\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    if density == \"high\":\n",
        "        hot = random.sample(range(1, A+1), k=max(1, A//5))\n",
        "        xs = np.random.choice(hot, size=n, replace=True)\n",
        "    elif density == \"medium\":\n",
        "        hot = random.sample(range(1, A+1), k=max(1, A//4))\n",
        "        xs = np.where(np.random.rand(n) < 0.55,\n",
        "                      np.random.choice(hot, size=n, replace=True),\n",
        "                      np.random.randint(1, A+1, size=n))\n",
        "    else:\n",
        "        xs = np.random.randint(1, A+1, size=n)\n",
        "\n",
        "    ys = np.random.randint(1, L, size=n)  # 1..L-1\n",
        "    coords = list(zip(xs.tolist(), ys.tolist()))\n",
        "\n",
        "    random.setstate(rnd_state)\n",
        "    np.random.set_state(np_state)\n",
        "    return coords\n",
        "\n",
        "def handover_candidates(A, L):\n",
        "    H = []\n",
        "    for x in range(1, A+1):\n",
        "        H.append((x,0))\n",
        "        H.append((x,L))\n",
        "    return H\n",
        "\n",
        "def choose_handover_for_point(pt, L):\n",
        "    x,y = pt\n",
        "    return (x,0) if y <= L/2 else (x,L)\n",
        "\n",
        "# -----------------------------\n",
        "# Reservation-based movement (node+edge)\n",
        "# time step = 1\n",
        "# node occupancy cap=1\n",
        "# edge occupancy prevents head-on swap: reserve (u,v,t) and (v,u,t)\n",
        "# -----------------------------\n",
        "class Reservation:\n",
        "    def __init__(self, cap=1):\n",
        "        self.cap = cap\n",
        "        self.node_occ = defaultdict(int)   # (node,t)->count\n",
        "        self.edge_occ = set()              # (u,v,t)\n",
        "\n",
        "    def can_enter(self, v, t):\n",
        "        return self.node_occ[(v,t)] < self.cap\n",
        "\n",
        "    def can_traverse(self, u, v, t):\n",
        "        # forbid using same directed edge at same time and forbid head-on swap\n",
        "        return ((u,v,t) not in self.edge_occ) and ((v,u,t) not in self.edge_occ)\n",
        "\n",
        "    def reserve_step(self, u, v, t):\n",
        "        # reserve arrival node at t+1 and edge at t\n",
        "        self.node_occ[(v, t+1)] += 1\n",
        "        self.edge_occ.add((u, v, t))\n",
        "\n",
        "    def move_one(self, u, v, t):\n",
        "        # wait until feasible\n",
        "        while not (self.can_traverse(u,v,t) and self.can_enter(v,t+1)):\n",
        "            t += 1\n",
        "        self.reserve_step(u,v,t)\n",
        "        return t+1\n",
        "\n",
        "# -----------------------------\n",
        "# Shortest path on Manhattan grid (no obstacles)\n",
        "# We use simple axis-first path (x then y) which is optimal in Manhattan distance.\n",
        "# -----------------------------\n",
        "def manhattan_path(u, v):\n",
        "    (x1,y1),(x2,y2) = u, v\n",
        "    path = [u]\n",
        "    x, y = x1, y1\n",
        "    # move in x\n",
        "    dx = 1 if x2 > x else -1\n",
        "    while x != x2:\n",
        "        x += dx\n",
        "        path.append((x,y))\n",
        "    # move in y\n",
        "    dy = 1 if y2 > y else -1\n",
        "    while y != y2:\n",
        "        y += dy\n",
        "        path.append((x,y))\n",
        "    return path\n",
        "\n",
        "def travel_with_reservation(res: Reservation, u, v, t0, speed=1.0):\n",
        "    # speed>1 => fewer timesteps per Manhattan unit; we approximate by scaling time increments.\n",
        "    # To keep discrete reservations consistent, we convert speed into stochastic \"skip\" only via time dilation:\n",
        "    # effective duration = ceil(dist/speed). But conflicts still handled step-by-step.\n",
        "    # Implementation: run step-by-step then compress? Not valid with reservations.\n",
        "    # So we keep step-by-step but allow robot to \"attempt\" to move twice in a time unit when speed>1\n",
        "    # by doing k moves per tick. Simple & consistent:\n",
        "    path = manhattan_path(u,v)\n",
        "    t = t0\n",
        "    if speed <= 1.000001:\n",
        "        for i in range(len(path)-1):\n",
        "            t = res.move_one(path[i], path[i+1], t)\n",
        "        return t\n",
        "    # speed>1: do multi-steps per time tick, still respecting reservations.\n",
        "    # We simulate micro-steps: allow up to floor(speed) extra moves; fractional handled probabilistically.\n",
        "    k = int(speed)\n",
        "    frac = speed - k\n",
        "    i = 0\n",
        "    while i < len(path)-1:\n",
        "        moves_this_tick = k\n",
        "        if random.random() < frac:\n",
        "            moves_this_tick += 1\n",
        "        # do moves_this_tick sequential moves starting at current t, but each move consumes 1 time unit in reservation\n",
        "        # (discrete-time): so benefit comes only from reduced waiting vs. longer routes; still ok as approximation.\n",
        "        # If you want strict speed, use continuous-time simulator; EJOR typically accepts discrete-time with speed ratio.\n",
        "        for _ in range(moves_this_tick):\n",
        "            if i >= len(path)-1: break\n",
        "            t = res.move_one(path[i], path[i+1], t)\n",
        "            i += 1\n",
        "    return t\n",
        "\n",
        "# -----------------------------\n",
        "# Picker batching and route building (S-shape-ish)\n",
        "# Assign items to pickers by aisle and round-robin to balance\n",
        "# Then within picker: sort by (x,y) and batch consecutive picks\n",
        "# -----------------------------\n",
        "def assign_items_to_pickers(coords, P):\n",
        "    order = sorted(range(len(coords)), key=lambda i: (coords[i][0], coords[i][1]))\n",
        "    buckets = [[] for _ in range(P)]\n",
        "    for k, idx in enumerate(order):\n",
        "        buckets[k % P].append(idx)\n",
        "    return buckets\n",
        "\n",
        "def picker_batches(coords, idxs, batch_size):\n",
        "    seq = [coords[i] for i in idxs]\n",
        "    # simple order already sorted externally; we can refine by nearest neighbor within aisle but keep stable\n",
        "    batches = [seq[i:i+batch_size] for i in range(0, len(seq), batch_size)]\n",
        "    return batches\n",
        "\n",
        "# -----------------------------\n",
        "# Decision variables for solution:\n",
        "# - for each picker batch (p,b): chosen handover h in { (x,0),(x,L) } where x = aisle of last item in batch\n",
        "# - assign handovers to robots (many-to-one)\n",
        "# - robot route order (sequence of handovers per robot)\n",
        "# -----------------------------\n",
        "def build_initial_solution(inst, P, R):\n",
        "    coords = inst[\"coords\"]\n",
        "    A, L = inst[\"A\"], inst[\"L\"]\n",
        "    buckets = assign_items_to_pickers(coords, P)\n",
        "  # build batches and default handovers (nearest end for last item)\n",
        "    batches = {}\n",
        "    batch_h = {}     # (p,b)->handover\n",
        "    all_handovers = set()\n",
        "\n",
        "    for p in range(P):\n",
        "        b = picker_batches(coords, buckets[p], BATCH_SIZE)\n",
        "        batches[p] = b\n",
        "        for bi, items in enumerate(b):\n",
        "            last = items[-1]\n",
        "            h = choose_handover_for_point(last, L)\n",
        "            batch_h[(p,bi)] = h\n",
        "            all_handovers.add(h)\n",
        "\n",
        "    # robot assignment: greedy balancing by load (#batches per handover)\n",
        "    load = defaultdict(int)\n",
        "    for hb in batch_h.values():\n",
        "        load[hb] += 1\n",
        "\n",
        "    robots_h = {r:[] for r in range(R)}\n",
        "    rload = {r:0 for r in range(R)}\n",
        "    for h, l in sorted(load.items(), key=lambda x:x[1], reverse=True):\n",
        "        rr = min(rload, key=lambda k:rload[k])\n",
        "        robots_h[rr].append(h)\n",
        "        rload[rr] += l\n",
        "\n",
        "    # robot route per robot: sort by x then y (baseline)\n",
        "    robot_route = {}\n",
        "    for r in range(R):\n",
        "        hs = robots_h[r]\n",
        "        robot_route[r] = sorted(hs, key=lambda t:(t[0], t[1]))\n",
        "\n",
        "    return {\n",
        "        \"batches\": batches,\n",
        "        \"batch_h\": dict(batch_h),\n",
        "        \"robots_h\": {r:list(hs) for r,hs in robots_h.items()},\n",
        "        \"robot_route\": {r:list(rt) for r,rt in robot_route.items()},\n",
        "    }\n",
        "\n",
        "def deepcopy_sol(sol):\n",
        "    return {\n",
        "        \"batches\": sol[\"batches\"],  # static structure per (inst,P)\n",
        "        \"batch_h\": dict(sol[\"batch_h\"]),\n",
        "        \"robots_h\": {r:list(hs) for r,hs in sol[\"robots_h\"].items()},\n",
        "        \"robot_route\": {r:list(rt) for r,rt in sol[\"robot_route\"].items()},\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Event-based synchronized simulation\n",
        "# - Pickers execute: depot -> items in batch -> selected handover, meeting\n",
        "# - Robots execute: depot -> visit their assigned handovers in route order\n",
        "# - Meetings are served FIFO at handover when both present; service time applies.\n",
        "# - Congestion via reservation conflicts (cap=1) in narrow aisles (implicitly because all moves are reserved)\n",
        "# -----------------------------\n",
        "def simulate(inst, P, R, sol, sync=True, congestion=True):\n",
        "\n",
        "    A, L = inst[\"A\"], inst[\"L\"]\n",
        "    coords = inst[\"coords\"]\n",
        "\n",
        "    # --- FIX: eksik batch_h tamamla ---\n",
        "    for p in range(P):\n",
        "        batches = sol[\"batches\"][p]\n",
        "        for bi in range(len(batches)):\n",
        "            if (p, bi) not in sol[\"batch_h\"]:\n",
        "                last = batches[bi][-1]\n",
        "                x, y = last\n",
        "                sol[\"batch_h\"][(p, bi)] = (x, 0) if y <= L/2 else (x, L)\n",
        "\n",
        "    depot = (0, 0)\n",
        "    res = Reservation(cap=CAP if congestion else 999999)\n",
        "\n",
        "    meetings_at = defaultdict(list)\n",
        "\n",
        "    picker_finish = [0] * P\n",
        "    robot_wait_total = 0\n",
        "\n",
        "    # -----------------------------\n",
        "    # PICKERS\n",
        "    # -----------------------------\n",
        "    for p in range(P):\n",
        "        t = 0\n",
        "        cur = depot\n",
        "        batches = sol[\"batches\"][p]\n",
        "\n",
        "        for bi, items in enumerate(batches):\n",
        "            remaining = items.copy()\n",
        "\n",
        "            while remaining:\n",
        "                nxt = min(remaining, key=lambda v: abs(v[0]-cur[0]) + abs(v[1]-cur[1]))\n",
        "                remaining.remove(nxt)\n",
        "                t = travel_with_reservation(res, cur, nxt, t)\n",
        "                cur = nxt\n",
        "\n",
        "            h = sol[\"batch_h\"][(p, bi)]\n",
        "            t = travel_with_reservation(res, cur, h, t)\n",
        "            cur = h\n",
        "\n",
        "            meetings_at[h].append([p, t, bi])\n",
        "\n",
        "        t = travel_with_reservation(res, cur, depot, t)\n",
        "        picker_finish[p] = t\n",
        "\n",
        "    # -----------------------------\n",
        "    # ROBOTS\n",
        "    # -----------------------------\n",
        "    robot_finish = [0] * R\n",
        "\n",
        "    for h in meetings_at:\n",
        "        meetings_at[h].sort(key=lambda x: x[1])\n",
        "\n",
        "    for r in range(R):\n",
        "        t = 0\n",
        "        cur = depot\n",
        "        route = sol[\"robot_route\"][r]\n",
        "\n",
        "        for h in route:\n",
        "            t = travel_with_reservation(res, cur, h, t)\n",
        "            cur = h\n",
        "\n",
        "            if not sync:\n",
        "                continue\n",
        "\n",
        "            q = meetings_at.get(h, [])\n",
        "\n",
        "            while q:\n",
        "                p, parr, bi = q[0]\n",
        "\n",
        "                if t < parr:\n",
        "                    robot_wait_total += (parr - t)\n",
        "                    t = parr\n",
        "\n",
        "                t += SERVICE\n",
        "                q.pop(0)\n",
        "\n",
        "        t = travel_with_reservation(res, cur, depot, t)\n",
        "        robot_finish[r] = t\n",
        "\n",
        "    makespan = max(max(picker_finish), max(robot_finish))\n",
        "    total_wait = robot_wait_total\n",
        "\n",
        "    return makespan, total_wait, robot_wait_total\n",
        "\n",
        "# -----------------------------\n",
        "# Baselines\n",
        "# -----------------------------\n",
        "def eval_method(inst, P, R, sol, method):\n",
        "    if method == \"Integrated\":\n",
        "        return simulate(inst,P,R,sol, sync=True,  congestion=True)\n",
        "    if method == \"NoCongestion\":\n",
        "        return simulate(inst,P,R,sol, sync=True,  congestion=False)\n",
        "    if method == \"NoSync\":\n",
        "        return simulate(inst,P,R,sol, sync=False, congestion=True)\n",
        "    if method == \"Sequential\":\n",
        "        return simulate(inst,P,R,sol, sync=False, congestion=False)\n",
        "    raise ValueError(\"Unknown method\")\n",
        "\n",
        "# -----------------------------\n",
        "# ALNS: operators on batch_h, robots_h, robot_route\n",
        "# Destroy operators:\n",
        "# - RandomBatchH: remove handover assignments for fraction of batches\n",
        "# - HotspotH: remove assignments for most-loaded handover\n",
        "# - RobotRouteShake: remove subsequence from robot route\n",
        "# Repair operators:\n",
        "# - GreedyH: choose better of (x,0)/(x,L) for removed batches using quick proxy cost\n",
        "# - RebalanceRobots: reassign handovers to robots by load\n",
        "# - RegretInsertRoute: rebuild robot route with regret insertion (approx TSP)\n",
        "# -----------------------------\n",
        "def proxy_batch_cost(last_item, h, depot=(0,0)):\n",
        "    return manhattan(last_item,h) + manhattan(h,depot)\n",
        "\n",
        "def rebuild_robots_h_from_batchh(sol, R):\n",
        "    load = defaultdict(int)\n",
        "    for h in sol[\"batch_h\"].values():\n",
        "        load[h] += 1\n",
        "    robots_h = {r:[] for r in range(R)}\n",
        "    rload = {r:0 for r in range(R)}\n",
        "    for h,l in sorted(load.items(), key=lambda x:x[1], reverse=True):\n",
        "        rr = min(rload, key=lambda k:rload[k])\n",
        "        robots_h[rr].append(h)\n",
        "        rload[rr] += l\n",
        "    sol[\"robots_h\"] = {r:list(hs) for r,hs in robots_h.items()}\n",
        "\n",
        "def route_cost(route, depot=(0,0)):\n",
        "    if not route: return 0\n",
        "    cur = depot\n",
        "    c = 0\n",
        "    for h in route:\n",
        "        c += manhattan(cur,h)\n",
        "        cur = h\n",
        "    c += manhattan(cur,depot)\n",
        "    return c\n",
        "\n",
        "def regret_insert_route(handovers, depot=(0,0), k=2):\n",
        "    # Build route incrementally using regret-k insertion (k=2)\n",
        "    if not handovers: return []\n",
        "    route = [handovers[0]]\n",
        "    remaining = handovers[1:]\n",
        "    while remaining:\n",
        "        best_choice = None\n",
        "        best_regret = -1e18\n",
        "        for h in remaining:\n",
        "            # evaluate insertion positions\n",
        "            costs = []\n",
        "            for pos in range(len(route)+1):\n",
        "                cand = route[:pos] + [h] + route[pos:]\n",
        "                costs.append(route_cost(cand, depot))\n",
        "            costs_sorted = sorted(costs)\n",
        "            regret = costs_sorted[min(k-1,len(costs_sorted)-1)] - costs_sorted[0]\n",
        "            # choose max regret; tie by best insertion cost\n",
        "            if regret > best_regret:\n",
        "                best_regret = regret\n",
        "                best_choice = (h, costs.index(min(costs)), min(costs))\n",
        "        h, pos, _ = best_choice\n",
        "        route = route[:pos] + [h] + route[pos:]\n",
        "        remaining.remove(h)\n",
        "    return route\n",
        "\n",
        "class ALNSRunner:\n",
        "    def __init__(self, inst, P, R):\n",
        "        self.inst=inst; self.P=P; self.R=R\n",
        "        self.cur = build_initial_solution(inst,P,R)\n",
        "        self.best = deepcopy_sol(self.cur)\n",
        "        self.best_val = None\n",
        "\n",
        "        self.destroy_ops = [\"RandomBatchH\",\"HotspotH\",\"RobotRouteShake\"]\n",
        "        self.repair_ops  = [\"GreedyH\",\"RebalanceRobots\",\"RegretInsertRoute\"]\n",
        "\n",
        "        self.wd = {op:1.0 for op in self.destroy_ops}\n",
        "        self.wr = {op:1.0 for op in self.repair_ops}\n",
        "\n",
        "    def pick(self, w):\n",
        "        ops=list(w.keys())\n",
        "        ww=np.array([w[o] for o in ops], float)\n",
        "        ww = ww / ww.sum()\n",
        "        return np.random.choice(ops, p=ww)\n",
        "\n",
        "    def destroy(self, sol, op):\n",
        "        removed_batches=[]\n",
        "        if op==\"RandomBatchH\":\n",
        "            keys=list(sol[\"batch_h\"].keys())\n",
        "            m=max(1, int(0.12*len(keys)))\n",
        "            removed_batches = random.sample(keys, m)\n",
        "            for k in removed_batches:\n",
        "                sol[\"batch_h\"].pop(k, None)\n",
        "\n",
        "        elif op==\"HotspotH\":\n",
        "            load=defaultdict(int)\n",
        "            for k,h in sol[\"batch_h\"].items():\n",
        "                load[h]+=1\n",
        "            if load:\n",
        "                hmax=max(load, key=lambda h:load[h])\n",
        "                keys=[k for k,h in sol[\"batch_h\"].items() if h==hmax]\n",
        "                m=max(1, int(0.25*len(keys)))\n",
        "                removed_batches=random.sample(keys,m)\n",
        "                for k in removed_batches:\n",
        "                    sol[\"batch_h\"].pop(k, None)\n",
        "\n",
        "        elif op==\"RobotRouteShake\":\n",
        "            # remove a chunk from one robot route (forces rebuild)\n",
        "            r = random.randrange(self.R)\n",
        "            rt = sol[\"robot_route\"][r]\n",
        "            if len(rt) >= 4:\n",
        "                i = random.randint(0, len(rt)-2)\n",
        "                j = random.randint(i+1, min(len(rt), i+1+max(2,len(rt)//4)))\n",
        "                # removed handovers become \"unrouted\" but still assigned via robots_h; we handle by rebuild route repair\n",
        "                del rt[i:j]\n",
        "                sol[\"robot_route\"][r]=rt\n",
        "\n",
        "        return removed_batches\n",
        "\n",
        "    def repair(self, sol, removed_batches, op):\n",
        "        coords=self.inst[\"coords\"]; L=self.inst[\"L\"]\n",
        "\n",
        "        if op==\"GreedyH\":\n",
        "            # For missing batch handovers, choose best of two ends based on proxy\n",
        "            for (p,bi) in removed_batches:\n",
        "                last = sol[\"batches\"][p][bi][-1]\n",
        "                x,_ = last\n",
        "                h1=(x,0); h2=(x,L)\n",
        "                c1=proxy_batch_cost(last,h1); c2=proxy_batch_cost(last,h2)\n",
        "                sol[\"batch_h\"][(p,bi)] = h1 if c1<=c2 else h2\n",
        "\n",
        "        elif op==\"RebalanceRobots\":\n",
        "            rebuild_robots_h_from_batchh(sol, self.R)\n",
        "\n",
        "        elif op==\"RegretInsertRoute\":\n",
        "            # rebuild each robot route from its assigned handovers using regret insertion\n",
        "            for r in range(self.R):\n",
        "                hs = list(set(sol[\"robots_h\"].get(r, [])))\n",
        "                if not hs:\n",
        "                    sol[\"robot_route\"][r]=[]\n",
        "                else:\n",
        "                    # start with a random handover to diversify\n",
        "                    random.shuffle(hs)\n",
        "                    sol[\"robot_route\"][r]=regret_insert_route(hs, depot=(0,0), k=2)\n",
        "\n",
        "        # always keep robots_h consistent (some ops may have broken it)\n",
        "        rebuild_robots_h_from_batchh(sol, self.R)\n",
        "        return sol\n",
        "\n",
        "    def objective(self, makespan, total_wait):\n",
        "        # scalarization; adjust lambda as you like\n",
        "        return makespan + 0.02*total_wait\n",
        "\n",
        "    def run(self, iters=ALNS_ITERS):\n",
        "        # initial evaluate\n",
        "        mk, tw, rw = simulate(self.inst, self.P, self.R, self.cur, sync=True, congestion=True)\n",
        "        cur_val = self.objective(mk, tw)\n",
        "\n",
        "        self.best = deepcopy_sol(self.cur)\n",
        "        self.best_val = cur_val\n",
        "        best_mk, best_tw = mk, tw\n",
        "\n",
        "        T = T0\n",
        "        hist=[]\n",
        "\n",
        "        for it in range(1,iters+1):\n",
        "            d = self.pick(self.wd)\n",
        "            r = self.pick(self.wr)\n",
        "\n",
        "            cand = deepcopy_sol(self.cur)\n",
        "            removed = self.destroy(cand, d)\n",
        "            cand = self.repair(cand, removed, r)\n",
        "\n",
        "            mk2, tw2, rw2 = simulate(self.inst, self.P, self.R, cand, sync=True, congestion=True)\n",
        "            cand_val = self.objective(mk2, tw2)\n",
        "\n",
        "            # SA acceptance\n",
        "            accept = (cand_val <= cur_val) or (random.random() < math.exp(-(cand_val-cur_val)/(T+1e-9)))\n",
        "            if accept:\n",
        "                self.cur = cand\n",
        "                cur_val = cand_val\n",
        "\n",
        "            if cand_val < self.best_val:\n",
        "                self.best = deepcopy_sol(cand)\n",
        "                self.best_val = cand_val\n",
        "                best_mk, best_tw = mk2, tw2\n",
        "                self.wd[d] += 2.0\n",
        "                self.wr[r] += 2.0\n",
        "            else:\n",
        "                self.wd[d] += 0.03\n",
        "                self.wr[r] += 0.03\n",
        "\n",
        "            if it % 250 == 0:\n",
        "                # mild weight decay\n",
        "                for op in self.wd: self.wd[op] = max(0.1, self.wd[op]*0.9)\n",
        "                for op in self.wr: self.wr[op] = max(0.1, self.wr[op]*0.9)\n",
        "\n",
        "            if it % 10 == 0:\n",
        "                hist.append((it, self.best_val, best_mk, best_tw))\n",
        "\n",
        "            T *= COOL\n",
        "\n",
        "        hist_df = pd.DataFrame(hist, columns=[\"iter\",\"best_obj\",\"best_makespan\",\"best_total_wait\"])\n",
        "        return self.best, best_mk, best_tw, hist_df\n",
        "\n",
        "# -----------------------------\n",
        "# Run full experiment\n",
        "# -----------------------------\n",
        "instances=[]\n",
        "iid=0\n",
        "for A in AISLES:\n",
        "    for n in ITEMS:\n",
        "        for d in DENS:\n",
        "            for s in range(SEEDS_PER):\n",
        "                iid+=1\n",
        "                seed = 10000 + iid*17 + s\n",
        "                coords = gen_items(A, AISLE_LEN, n, d, seed)\n",
        "                instances.append({\n",
        "                    \"instance_id\": f\"I{iid:04d}\",\n",
        "                    \"seed\": seed,\n",
        "                    \"A\": A,\n",
        "                    \"L\": AISLE_LEN,\n",
        "                    \"n_items\": n,\n",
        "                    \"density\": d,\n",
        "                    \"coords\": coords\n",
        "                })\n",
        "\n",
        "inst_df = pd.DataFrame([{k:v for k,v in inst.items() if k!=\"coords\"} for inst in instances])\n",
        "\n",
        "results=[]\n",
        "conv_store=[]\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "# Baselines on all instances/configs\n",
        "for inst in instances:\n",
        "    for P in P_LIST:\n",
        "        for R in R_LIST:\n",
        "            sol0 = build_initial_solution(inst,P,R)\n",
        "\n",
        "            for m in [\"Integrated\",\"NoCongestion\",\"NoSync\",\"Sequential\"]:\n",
        "                mk, tw, rw = eval_method(inst,P,R,sol0,m)\n",
        "                results.append({\n",
        "                    \"instance_id\": inst[\"instance_id\"], \"A\":inst[\"A\"], \"n_items\":inst[\"n_items\"], \"density\":inst[\"density\"],\n",
        "                    \"cap\": CAP, \"pickers\":P, \"robots\":R, \"method\":m,\n",
        "                    \"makespan\": mk, \"total_wait\": tw, \"robot_wait\": rw, \"cpu_s\": 0.0\n",
        "                })\n",
        "\n",
        "# ALNS on a “hard subset” for EJOR-quality improvements + fleet-size insight + convergence\n",
        "hard_subset = [inst for inst in instances if (inst[\"A\"]==40 and inst[\"density\"] in (\"medium\",\"high\") and inst[\"n_items\"]==max(ITEMS))]\n",
        "hard_subset = hard_subset[: min(6, len(hard_subset))]  # keep bounded; increase later for final paper runs\n",
        "\n",
        "for inst in hard_subset:\n",
        "    # do ALNS mainly for P=5 across fleet sizes (Figure 2)\n",
        "    for R in R_LIST:\n",
        "        runner = ALNSRunner(inst, P=5, R=R)\n",
        "        t0=time.time()\n",
        "        best_sol, mk, tw, hist = runner.run(iters=ALNS_ITERS)\n",
        "        cpu=time.time()-t0\n",
        "        results.append({\n",
        "            \"instance_id\": inst[\"instance_id\"], \"A\":inst[\"A\"], \"n_items\":inst[\"n_items\"], \"density\":inst[\"density\"],\n",
        "            \"cap\": CAP, \"pickers\":5, \"robots\":R, \"method\":\"Integrated-ALNS\",\n",
        "            \"makespan\": mk, \"total_wait\": tw, \"robot_wait\": tw, \"cpu_s\": cpu\n",
        "        })\n",
        "        if R==3:  # store one convergence per instance\n",
        "            h=hist.copy()\n",
        "            h[\"instance_id\"]=inst[\"instance_id\"]\n",
        "            h[\"robots\"]=R\n",
        "            conv_store.append(h)\n",
        "\n",
        "elapsed = time.time()-t_start\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "\n",
        "# -----------------------------\n",
        "# Tables & Figures (paper-ready)\n",
        "# -----------------------------\n",
        "# Table 1: method comparison (baselines only)\n",
        "table1 = res_df[res_df[\"method\"].isin([\"Integrated\",\"NoCongestion\",\"NoSync\",\"Sequential\"])].groupby(\"method\", as_index=False).agg(\n",
        "    avg_makespan=(\"makespan\",\"mean\"),\n",
        "    std_makespan=(\"makespan\",\"std\"),\n",
        "    avg_total_wait=(\"total_wait\",\"mean\"),\n",
        "    std_total_wait=(\"total_wait\",\"std\"),\n",
        "    n=(\"makespan\",\"count\")\n",
        ")\n",
        "\n",
        "# Table 2: fleet size effect\n",
        "table2_g = res_df[res_df[\"method\"]==\"Integrated\"].groupby([\"pickers\",\"robots\"], as_index=False).agg(\n",
        "    avg_makespan=(\"makespan\",\"mean\"),\n",
        "    avg_total_wait=(\"total_wait\",\"mean\")\n",
        ")\n",
        "table2_a = res_df[res_df[\"method\"]==\"Integrated-ALNS\"].groupby([\"pickers\",\"robots\"], as_index=False).agg(\n",
        "    avg_makespan=(\"makespan\",\"mean\"),\n",
        "    avg_total_wait=(\"total_wait\",\"mean\"),\n",
        "    avg_cpu_s=(\"cpu_s\",\"mean\")\n",
        ")\n",
        "\n",
        "# Figure 2: fleet size effect (Integrated baseline + ALNS overlay)\n",
        "fig_df = res_df[res_df[\"method\"]==\"Integrated\"].groupby([\"pickers\",\"robots\"], as_index=False)[\"makespan\"].mean()\n",
        "plt.figure()\n",
        "for P in sorted(fig_df[\"pickers\"].unique()):\n",
        "    sub = fig_df[fig_df[\"pickers\"]==P].sort_values(\"robots\")\n",
        "    plt.plot(sub[\"robots\"], sub[\"makespan\"], marker=\"o\", label=f\"Integrated, P={P}\")\n",
        "subA = res_df[res_df[\"method\"]==\"Integrated-ALNS\"].groupby([\"robots\"], as_index=False)[\"makespan\"].mean().sort_values(\"robots\")\n",
        "if len(subA):\n",
        "    plt.plot(subA[\"robots\"], subA[\"makespan\"], marker=\"o\", linestyle=\"--\", label=\"ALNS, P=5 (hard subset)\")\n",
        "plt.xlabel(\"Robots\")\n",
        "plt.ylabel(\"Makespan (time units)\")\n",
        "plt.title(\"Figure 2. Effect of robot fleet size on makespan under narrow-aisle congestion (cap=1)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figure2.png\")\n",
        "plt.close()\n",
        "\n",
        "# Convergence figure (avg)\n",
        "if conv_store:\n",
        "    conv = pd.concat(conv_store, ignore_index=True)\n",
        "    avg = conv.groupby(\"iter\", as_index=False)[\"best_makespan\"].mean()\n",
        "    plt.figure()\n",
        "    plt.plot(avg[\"iter\"], avg[\"best_makespan\"])\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Average best makespan\")\n",
        "    plt.title(\"ALNS convergence (average across sample runs)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figure_convergence.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Save Excel outputs\n",
        "inst_df.to_excel(\"dataset_instances.xlsx\", index=False)\n",
        "res_df.to_excel(\"results_table.xlsx\", index=False)\n",
        "table1.to_excel(\"Table1_method_comparison.xlsx\", index=False)\n",
        "\n",
        "with pd.ExcelWriter(\"Table2_fleet_size.xlsx\") as w:\n",
        "    table2_g.to_excel(w, sheet_name=\"Integrated_All\", index=False)\n",
        "    table2_a.to_excel(w, sheet_name=\"ALNS_Subset\", index=False)\n",
        "\n",
        "# Save a run log\n",
        "with open(\"run_log.txt\",\"w\") as f:\n",
        "    f.write(f\"Elapsed seconds: {elapsed:.2f}\\n\")\n",
        "    f.write(f\"Instances: {len(instances)}\\n\")\n",
        "    f.write(f\"Hard subset (ALNS): {len(hard_subset)}\\n\")\n",
        "    f.write(f\"ALNS iters: {ALNS_ITERS}\\n\")\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"Files written: dataset_instances.xlsx, results_table.xlsx, Table1_method_comparison.xlsx, Table2_fleet_size.xlsx, figure2.png, figure_convergence.png, run_log.txt\")\n",
        "\n",
        "# Colab download helper\n",
        "try:\n",
        "    from google.colab import files\n",
        "    for fn in [\"dataset_instances.xlsx\",\"results_table.xlsx\",\"Table1_method_comparison.xlsx\",\"Table2_fleet_size.xlsx\",\n",
        "               \"figure2.png\",\"figure_convergence.png\",\"run_log.txt\"]:\n",
        "        files.download(fn)\n",
        "except Exception as e:\n",
        "    print(\"Not in Colab or download unavailable:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "17BYmCfN1GsE",
        "outputId": "e6a04510-f12b-46ec-b0d7-2b0c7fbaafd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n",
            "Files written: dataset_instances.xlsx, results_table.xlsx, Table1_method_comparison.xlsx, Table2_fleet_size.xlsx, figure2.png, figure_convergence.png, run_log.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1c3eda8-711f-4789-af45-a7f59515a656\", \"dataset_instances.xlsx\", 7432)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_17a2acac-9d8c-45be-8dd6-20c4bce78860\", \"results_table.xlsx\", 191048)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_57788b24-c88f-4adb-aef9-9c9fc999c9b1\", \"Table1_method_comparison.xlsx\", 5245)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6a5bc018-18f5-44b8-b21c-73f88113fea4\", \"Table2_fleet_size.xlsx\", 6043)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_287de9a8-2033-401c-8348-4ad42b01af48\", \"figure2.png\", 46599)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a30569d3-9c7a-4ac1-b5ea-51119af79729\", \"figure_convergence.png\", 27404)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e32e8e18-46e7-4eeb-b76f-b786d3f5bc2f\", \"run_log.txt\", 77)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}